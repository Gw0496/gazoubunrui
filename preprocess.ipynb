{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocess.ipynb",
      "provenance": [],
      "mount_file_id": "1xnpCr1kDHPvvhg_Iq84JFF1P3p8EVX9Y",
      "authorship_tag": "ABX9TyPh402XuUq8Bdrp0OtIdEz5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gw0496/gazoubunrui/blob/master/preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP-e3PQw0_aK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "0b140811-58fc-4fcc-802a-0a260d0768f8"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/gazoubunrui')\n",
        "\n",
        "import ic_module as ic\n",
        "import os.path as op\n",
        "\n",
        "i = 0\n",
        "for filename in ic.FileNames :\n",
        "    # ディレクトリ名入力\n",
        "    while True :\n",
        "        dirname = input(\">>「\" + ic.ClassNames[i] + \"」の画像のあるディレクトリ ： \")\n",
        "        if op.isdir(dirname) :\n",
        "            break\n",
        "        print(\">> そのディレクトリは存在しません！\")\n",
        "\n",
        "    # 関数実行\n",
        "    ic.PreProcess(dirname, filename, var_amount=3)\n",
        "    i += 1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>「hara」の画像のあるディレクトリ ： /content/drive/My Drive/ColabData/face/hara\n",
            ">> /content/drive/My Drive/ColabData/face/haraから36個のファイル読み込み成功\n",
            ">>「koiwai」の画像のあるディレクトリ ： /content/drive/My Drive/ColabData/face/koiwai\n",
            ">> /content/drive/My Drive/ColabData/face/koiwaiから23個のファイル読み込み成功\n",
            ">>「shibuno」の画像のあるディレクトリ ： /content/drive/My Drive/ColabData/face/shibuno\n",
            ">> /content/drive/My Drive/ColabData/face/shibunoから37個のファイル読み込み成功\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuBgYgcq4BIa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42b58c63-9802-4c2b-bb4d-2d52b7cb7814"
      },
      "source": [
        "import ic_module as ic\n",
        "\n",
        "# 関数実行\n",
        "ic.Learning(tsnum=30, nb_epoch=50, batch_size=8, learn_schedule=0.9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> 学習サンプル数 :  (288, 32, 32, 3)\n",
            ">> 学習開始\n",
            "Epoch 1/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 1.1117 - accuracy: 0.4115\n",
            "Epoch 00001: val_loss improved from inf to 1.09543, saving model to best.hdf5\n",
            "25/25 [==============================] - 2s 66ms/step - loss: 1.1087 - accuracy: 0.4141 - val_loss: 1.0954 - val_accuracy: 0.3444\n",
            "Epoch 2/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 1.0488 - accuracy: 0.3958\n",
            "Epoch 00002: val_loss did not improve from 1.09543\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 1.0478 - accuracy: 0.3990 - val_loss: 1.1036 - val_accuracy: 0.3556\n",
            "Epoch 3/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 1.0439 - accuracy: 0.4427\n",
            "Epoch 00003: val_loss improved from 1.09543 to 1.07692, saving model to best.hdf5\n",
            "25/25 [==============================] - 1s 60ms/step - loss: 1.0432 - accuracy: 0.4394 - val_loss: 1.0769 - val_accuracy: 0.4556\n",
            "Epoch 4/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 1.0155 - accuracy: 0.4740\n",
            "Epoch 00004: val_loss improved from 1.07692 to 1.04987, saving model to best.hdf5\n",
            "25/25 [==============================] - 1s 60ms/step - loss: 1.0148 - accuracy: 0.4747 - val_loss: 1.0499 - val_accuracy: 0.3444\n",
            "Epoch 5/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.9760 - accuracy: 0.4635\n",
            "Epoch 00005: val_loss improved from 1.04987 to 1.04854, saving model to best.hdf5\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.9822 - accuracy: 0.4596 - val_loss: 1.0485 - val_accuracy: 0.4667\n",
            "Epoch 6/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.9721 - accuracy: 0.4688\n",
            "Epoch 00006: val_loss improved from 1.04854 to 0.99102, saving model to best.hdf5\n",
            "25/25 [==============================] - 2s 60ms/step - loss: 0.9784 - accuracy: 0.4747 - val_loss: 0.9910 - val_accuracy: 0.4778\n",
            "Epoch 7/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.9121 - accuracy: 0.5260\n",
            "Epoch 00007: val_loss improved from 0.99102 to 0.98904, saving model to best.hdf5\n",
            "25/25 [==============================] - 1s 60ms/step - loss: 0.9166 - accuracy: 0.5253 - val_loss: 0.9890 - val_accuracy: 0.4889\n",
            "Epoch 8/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.9870 - accuracy: 0.4583\n",
            "Epoch 00008: val_loss improved from 0.98904 to 0.88420, saving model to best.hdf5\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.9773 - accuracy: 0.4646 - val_loss: 0.8842 - val_accuracy: 0.6000\n",
            "Epoch 9/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.8862 - accuracy: 0.5781\n",
            "Epoch 00009: val_loss improved from 0.88420 to 0.83591, saving model to best.hdf5\n",
            "25/25 [==============================] - 2s 60ms/step - loss: 0.8893 - accuracy: 0.5707 - val_loss: 0.8359 - val_accuracy: 0.5889\n",
            "Epoch 10/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.8167 - accuracy: 0.5938\n",
            "Epoch 00010: val_loss improved from 0.83591 to 0.79485, saving model to best.hdf5\n",
            "25/25 [==============================] - 1s 60ms/step - loss: 0.8203 - accuracy: 0.5909 - val_loss: 0.7948 - val_accuracy: 0.6333\n",
            "Epoch 11/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.8102 - accuracy: 0.6302\n",
            "Epoch 00011: val_loss did not improve from 0.79485\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.8095 - accuracy: 0.6313 - val_loss: 0.8687 - val_accuracy: 0.4556\n",
            "Epoch 12/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.7801 - accuracy: 0.6198\n",
            "Epoch 00012: val_loss improved from 0.79485 to 0.65790, saving model to best.hdf5\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.7809 - accuracy: 0.6162 - val_loss: 0.6579 - val_accuracy: 0.8333\n",
            "Epoch 13/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.7455 - accuracy: 0.6719\n",
            "Epoch 00013: val_loss did not improve from 0.65790\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.7409 - accuracy: 0.6768 - val_loss: 0.7185 - val_accuracy: 0.7111\n",
            "Epoch 14/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.7270 - accuracy: 0.6771\n",
            "Epoch 00014: val_loss improved from 0.65790 to 0.62637, saving model to best.hdf5\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.7182 - accuracy: 0.6818 - val_loss: 0.6264 - val_accuracy: 0.7889\n",
            "Epoch 15/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.7068 - accuracy: 0.7240\n",
            "Epoch 00015: val_loss did not improve from 0.62637\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 0.7047 - accuracy: 0.7222 - val_loss: 0.6557 - val_accuracy: 0.7667\n",
            "Epoch 16/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.6286 - accuracy: 0.7292\n",
            "Epoch 00016: val_loss improved from 0.62637 to 0.61252, saving model to best.hdf5\n",
            "25/25 [==============================] - 2s 60ms/step - loss: 0.6273 - accuracy: 0.7323 - val_loss: 0.6125 - val_accuracy: 0.8222\n",
            "Epoch 17/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.5895 - accuracy: 0.7448\n",
            "Epoch 00017: val_loss improved from 0.61252 to 0.54838, saving model to best.hdf5\n",
            "25/25 [==============================] - 2s 60ms/step - loss: 0.5853 - accuracy: 0.7475 - val_loss: 0.5484 - val_accuracy: 0.8333\n",
            "Epoch 18/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.5483 - accuracy: 0.7656\n",
            "Epoch 00018: val_loss did not improve from 0.54838\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.5598 - accuracy: 0.7576 - val_loss: 0.5811 - val_accuracy: 0.8000\n",
            "Epoch 19/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.5307 - accuracy: 0.7969\n",
            "Epoch 00019: val_loss improved from 0.54838 to 0.52884, saving model to best.hdf5\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.5276 - accuracy: 0.7980 - val_loss: 0.5288 - val_accuracy: 0.8333\n",
            "Epoch 20/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.5602 - accuracy: 0.7708\n",
            "Epoch 00020: val_loss did not improve from 0.52884\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.5528 - accuracy: 0.7727 - val_loss: 0.5532 - val_accuracy: 0.8000\n",
            "Epoch 21/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.5148 - accuracy: 0.7708\n",
            "Epoch 00021: val_loss did not improve from 0.52884\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.5072 - accuracy: 0.7778 - val_loss: 0.5561 - val_accuracy: 0.8111\n",
            "Epoch 22/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.5276 - accuracy: 0.8021\n",
            "Epoch 00022: val_loss did not improve from 0.52884\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.5259 - accuracy: 0.8030 - val_loss: 0.5347 - val_accuracy: 0.8111\n",
            "Epoch 23/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.4531 - accuracy: 0.8281\n",
            "Epoch 00023: val_loss improved from 0.52884 to 0.50241, saving model to best.hdf5\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.4537 - accuracy: 0.8283 - val_loss: 0.5024 - val_accuracy: 0.8333\n",
            "Epoch 24/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.4685 - accuracy: 0.8177\n",
            "Epoch 00024: val_loss did not improve from 0.50241\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.4670 - accuracy: 0.8182 - val_loss: 0.5052 - val_accuracy: 0.8222\n",
            "Epoch 25/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.4391 - accuracy: 0.8281\n",
            "Epoch 00025: val_loss did not improve from 0.50241\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.4471 - accuracy: 0.8283 - val_loss: 0.5025 - val_accuracy: 0.8111\n",
            "Epoch 26/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.4121 - accuracy: 0.8542\n",
            "Epoch 00026: val_loss improved from 0.50241 to 0.49337, saving model to best.hdf5\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.4104 - accuracy: 0.8535 - val_loss: 0.4934 - val_accuracy: 0.8222\n",
            "Epoch 27/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.4137 - accuracy: 0.8177\n",
            "Epoch 00027: val_loss did not improve from 0.49337\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.4280 - accuracy: 0.8131 - val_loss: 0.5028 - val_accuracy: 0.8111\n",
            "Epoch 28/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.4019 - accuracy: 0.8333\n",
            "Epoch 00028: val_loss improved from 0.49337 to 0.49019, saving model to best.hdf5\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.3976 - accuracy: 0.8384 - val_loss: 0.4902 - val_accuracy: 0.8222\n",
            "Epoch 29/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.4120 - accuracy: 0.8646\n",
            "Epoch 00029: val_loss did not improve from 0.49019\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.4091 - accuracy: 0.8636 - val_loss: 0.4935 - val_accuracy: 0.8222\n",
            "Epoch 30/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.4043 - accuracy: 0.8594\n",
            "Epoch 00030: val_loss did not improve from 0.49019\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3985 - accuracy: 0.8636 - val_loss: 0.4914 - val_accuracy: 0.8111\n",
            "Epoch 31/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3948 - accuracy: 0.8594\n",
            "Epoch 00031: val_loss improved from 0.49019 to 0.48552, saving model to best.hdf5\n",
            "25/25 [==============================] - 2s 60ms/step - loss: 0.4037 - accuracy: 0.8586 - val_loss: 0.4855 - val_accuracy: 0.8444\n",
            "Epoch 32/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3599 - accuracy: 0.8542\n",
            "Epoch 00032: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3650 - accuracy: 0.8535 - val_loss: 0.4977 - val_accuracy: 0.8000\n",
            "Epoch 33/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.4165 - accuracy: 0.8646\n",
            "Epoch 00033: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.4141 - accuracy: 0.8636 - val_loss: 0.4997 - val_accuracy: 0.8333\n",
            "Epoch 34/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3957 - accuracy: 0.8542\n",
            "Epoch 00034: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3919 - accuracy: 0.8586 - val_loss: 0.5015 - val_accuracy: 0.8000\n",
            "Epoch 35/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3646 - accuracy: 0.8750\n",
            "Epoch 00035: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3567 - accuracy: 0.8788 - val_loss: 0.4982 - val_accuracy: 0.8111\n",
            "Epoch 36/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3697 - accuracy: 0.8698\n",
            "Epoch 00036: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3653 - accuracy: 0.8737 - val_loss: 0.4999 - val_accuracy: 0.8000\n",
            "Epoch 37/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3952 - accuracy: 0.8698\n",
            "Epoch 00037: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3941 - accuracy: 0.8687 - val_loss: 0.4996 - val_accuracy: 0.8222\n",
            "Epoch 38/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3756 - accuracy: 0.8698\n",
            "Epoch 00038: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3751 - accuracy: 0.8687 - val_loss: 0.4988 - val_accuracy: 0.8222\n",
            "Epoch 39/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3873 - accuracy: 0.8646\n",
            "Epoch 00039: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.4008 - accuracy: 0.8535 - val_loss: 0.4994 - val_accuracy: 0.8222\n",
            "Epoch 40/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3626 - accuracy: 0.8698\n",
            "Epoch 00040: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.3592 - accuracy: 0.8687 - val_loss: 0.5009 - val_accuracy: 0.8222\n",
            "Epoch 41/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3159 - accuracy: 0.8906\n",
            "Epoch 00041: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 1s 60ms/step - loss: 0.3459 - accuracy: 0.8788 - val_loss: 0.5016 - val_accuracy: 0.8111\n",
            "Epoch 42/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3614 - accuracy: 0.8542\n",
            "Epoch 00042: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.3570 - accuracy: 0.8586 - val_loss: 0.5003 - val_accuracy: 0.8111\n",
            "Epoch 43/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3697 - accuracy: 0.8438\n",
            "Epoch 00043: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.3606 - accuracy: 0.8485 - val_loss: 0.4966 - val_accuracy: 0.8111\n",
            "Epoch 44/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3926 - accuracy: 0.8490\n",
            "Epoch 00044: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 1s 59ms/step - loss: 0.3875 - accuracy: 0.8535 - val_loss: 0.4970 - val_accuracy: 0.8111\n",
            "Epoch 45/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3366 - accuracy: 0.8594\n",
            "Epoch 00045: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 2s 60ms/step - loss: 0.3328 - accuracy: 0.8636 - val_loss: 0.4973 - val_accuracy: 0.8111\n",
            "Epoch 46/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3132 - accuracy: 0.9167\n",
            "Epoch 00046: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3177 - accuracy: 0.9141 - val_loss: 0.4951 - val_accuracy: 0.8111\n",
            "Epoch 47/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3658 - accuracy: 0.8854\n",
            "Epoch 00047: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3762 - accuracy: 0.8737 - val_loss: 0.4943 - val_accuracy: 0.8111\n",
            "Epoch 48/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3317 - accuracy: 0.8854\n",
            "Epoch 00048: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3544 - accuracy: 0.8838 - val_loss: 0.4945 - val_accuracy: 0.8111\n",
            "Epoch 49/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3750 - accuracy: 0.8594\n",
            "Epoch 00049: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3733 - accuracy: 0.8586 - val_loss: 0.4955 - val_accuracy: 0.8111\n",
            "Epoch 50/50\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 0.3540 - accuracy: 0.8802\n",
            "Epoch 00050: val_loss did not improve from 0.48552\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.3640 - accuracy: 0.8687 - val_loss: 0.4950 - val_accuracy: 0.8111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrktzO604bTQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "e6918d57-d1a2-42ec-c8e4-4dcad351c0b8"
      },
      "source": [
        "import ic_module as ic\n",
        "import os.path as op\n",
        "\n",
        "while True:\n",
        "    while True:\n",
        "        imgname = input(\"\\n>> 入力したい画像ファイル(「END」で終了) ： \")\n",
        "        if op.isfile(imgname) or imgname == \"END\":\n",
        "            break\n",
        "        print(\">> そのファイルは存在しません！\")\n",
        "    if imgname == \"END\":\n",
        "        break\n",
        "\n",
        "    # 関数実行\n",
        "    ic.TestProcess(imgname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">> 入力したい画像ファイル(「END」で終了) ： /content/drive/My Drive/ColabData/facetest/shibuno/image_0.jpg\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff08b910a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            ">> 計算結果↓\n",
            "[[0.08329521 0.02268188 0.8940229 ]]\n",
            ">> この画像は「shibuno」です。\n",
            "\n",
            ">> 入力したい画像ファイル(「END」で終了) ： END\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1T8SMwN6sy1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "efdfec06-7e34-4a30-b3f2-92a8412d0d7d"
      },
      "source": [
        "import glob\n",
        "import ic_module2 as ic\n",
        "import os.path as op\n",
        "\n",
        "dirname = \"/content/drive/My Drive/ColabData/facetest/shibuno\"#input(\"フォルダ名：\")\n",
        "files = glob.glob(dirname + \"/*.jpg\")\n",
        "cn1 = 0; cn2 = 0;\n",
        "for imgname in files :\n",
        "    kind = ic.TestProcess(imgname)\n",
        "    if kind == 1:\n",
        "        cn2 += 1\n",
        "    cn1 += 1\n",
        "\n",
        "print(\"学習・非学習含め正答率は\" + str(cn2*1.0/cn1) + \"です。\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff08719f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            ">> 計算結果↓\n",
            "[[0.08329521 0.02268188 0.8940229 ]]\n",
            ">> この画像は「shibuno」です。\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff08713c2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            ">> 計算結果↓\n",
            "[[0.14083865 0.08072554 0.7784358 ]]\n",
            ">> この画像は「shibuno」です。\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff0837dd510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            ">> 計算結果↓\n",
            "[[0.7793922  0.00406013 0.21654771]]\n",
            ">> この画像は「hara」です。\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ff08386c488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            ">> 計算結果↓\n",
            "[[6.8129005e-04 7.3714071e-04 9.9858153e-01]]\n",
            ">> この画像は「shibuno」です。\n",
            "学習・非学習含め正答率は0.0です。\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}